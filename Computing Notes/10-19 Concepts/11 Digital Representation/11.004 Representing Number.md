The most common way to represent numbers in a computer system is by a string of [[21.010 Bits and Bytes|bits]] called a binary number

# Converting Binary to Decimal

### Weighted sum method
By adding together ALL [[21.010 Bits and Bytes#Decimal|decimal]] number values from right to left at postions with a 1:
E.g. 256 + 64 + 32 + 4 + 1 = 357$_1$$_0$ aka 357 as a decimal number.

| Decimal Digit Value | 256 | 128 | 64  | 32  | 16  | 8   | 4   | 2   | 1   |
| ------------------- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Binary Digit Value  | 1   | 0   | 1   | 1   | 0   | 0   | 1   | 0   | 1   |
# Converting Decimal to Binary
Keep dividing the number by 2, keeping track of the remainder until 0 is the result of the division.

| Division | Quotient | Remainder | Value |
| -------- | -------- | --------- | ----- |
| 19/2     | 9        | 1         | 2$^0$ |
| 9/2      | 4        | 1         | 2$^1$ |
| 4/2      | 2        | 0         | 2$^2$ |
| 2/2      | 1        | 0         | 2$^3$ |
| 1/2      | 0        | 1         | 2$^4$ |


